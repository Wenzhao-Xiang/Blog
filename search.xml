<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CVPR2021 安全AI挑战者计划第六期赛道2：ImageNet无限制对抗攻击 TOP 2 比赛思路</title>
      <link href="/Blog/2021/04/25/tianchi2021top2/"/>
      <url>/Blog/2021/04/25/tianchi2021top2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/Blog/assets/css/APlayer.min.css"><script src="/Blog/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/Blog/assets/js/Meting.min.js"></script><div align="center"><font size="6">CVPR2021 安全AI挑战者计划第六期赛道2：ImageNet无限制对抗攻击 TOP 2 比赛思路</font></div><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>深度神经网络在图像识别、自动驾驶和医学图像分析等领域得到广泛的应用。然而，深度神经网络在实际应用中面临诸多问题，最近的研究表明，深度神经网络非常容易受到对抗样本的攻击。现在研究主要关注的是p-范数下的攻击和防御，但是p-范数的扰动需要控制其扰动量来确保人眼无法察觉。而实际场景中，深度模型遇到的更多威胁来自于非限制扰动对抗样本，即攻击者在图像上进行大范围且可见的修改，使得模型误识别的同时不影响人的正常观察。</p><h2 id="赛题分析"><a href="#赛题分析" class="headerlink" title="赛题分析"></a>赛题分析</h2><p>1.由于比赛是无限制对抗攻击，没有对图像修改程度做出严格限定，但是图像质量和黑盒攻击的成功率之间存在平衡性问题。<br>2.传统的扰动方法在人眼观察下，具有较明显的差别，需要寻找新的思路解决这一问题。<br>3.比赛无法通过query的方式获取到黑盒模型的任何信息，对攻击的有效性提出了更高的挑战。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>在图像质量的评估上，人眼对高频信息的变化不敏感，而对低频信息的变化较为敏感，考虑将扰动转换到频域上，提升图像质量。傅里叶变换可以将图像从空间域转换到频域，有助于对信号不同频域信息的解耦，增强对图像质量的控制。</p><h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><p>1.在低频信号上设置更严格的修改限制，在高频信号上设置更宽松的限制，采用不同的学习步长进行优化。<br>2.CW损失函数[1]在表现上比cross-entropy损失函数更有优势。<br>3.引入适当的data augmentation的策略，这一策略主要参考DIM[2]在迁移性上所做出的改进。<br>4.没有使用FID[3]和LPIPS[4]指标作为损失函数的一部分，主要考虑到最后的评判标准是人眼，单纯拟合客观分帮助不是很明显，但是本方法的优点在于图像质量可以通过对不同频段信息的修改进行控制，所以可以通过参数调整，获得较高的图像质量。<br>5.为了提升模型在黑盒上的攻击能力，我们使用了ensemble方法将efficientnet[5]、vit[6]和resnest[7]等模型结合起来，在ensemble适量模型之后，黑盒的攻击能力有所提升。</p><h2 id="样本展示"><a href="#样本展示" class="headerlink" title="样本展示"></a>样本展示</h2><table><thead><tr><th>原图</th><th>对抗样本</th></tr></thead><tbody><tr><td><a href="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz269v29j20dw0dwwfu.jpg" data-fancybox="group" data-caption="0" class="fancybox"><img alt="0" title="0" data-src="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz269v29j20dw0dwwfu.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz3ahqb9j20dw0dwabk.jpg" data-fancybox="group" data-caption="0" class="fancybox"><img alt="0" title="0" data-src="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz3ahqb9j20dw0dwabk.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr><tr><td><a href="https://tvax2.sinaimg.cn/large/a0732b55ly1gpvz2g3tg2j20dw0dwq3r.jpg" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" title="9" data-src="https://tvax2.sinaimg.cn/large/a0732b55ly1gpvz2g3tg2j20dw0dwq3r.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva1.sinaimg.cn/large/a0732b55ly1gpvz3gisx5j20dw0dwab1.jpg" data-fancybox="group" data-caption="9" class="fancybox"><img alt="9" title="9" data-src="https://tva1.sinaimg.cn/large/a0732b55ly1gpvz3gisx5j20dw0dwab1.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr><tr><td><a href="https://tvax1.sinaimg.cn/large/a0732b55ly1gpvz33g51nj20dw0dw3yu.jpg" data-fancybox="group" data-caption="19" class="fancybox"><img alt="19" title="19" data-src="https://tvax1.sinaimg.cn/large/a0732b55ly1gpvz33g51nj20dw0dw3yu.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz3ln2ysj20dw0dw0t5.jpg" data-fancybox="group" data-caption="19" class="fancybox"><img alt="19" title="19" data-src="https://tva4.sinaimg.cn/large/a0732b55ly1gpvz3ln2ysj20dw0dw0t5.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]Carlini N, Wagner D. Towards evaluating the robustness of neural networks[C]//2017 ieee symposium on security and privacy (sp). IEEE, 2017: 39-57.</p><p>[2]Xie C, Zhang Z, Zhou Y, et al. Improving transferability of adversarial examples with input diversity[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 2730-2739.</p><p>[3]Heusel M, Ramsauer H, Unterthiner T, et al. Gans trained by a two time-scale update rule converge to a local nash equilibrium[J]. arXiv preprint arXiv:1706.08500, 2017.</p><p>[4]Zhang R, Isola P, Efros A A, et al. The unreasonable effectiveness of deep features as a perceptual metric[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 586-595.</p><p>[5]Tan M, Le Q. Efficientnet: Rethinking model scaling for convolutional neural networks[C]//International Conference on Machine Learning. PMLR, 2019: 6105-6114.</p><p>[6]Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale[J]. arXiv preprint arXiv:2010.11929, 2020.</p><p>[7]Zhang H, Wu C, Zhang Z, et al. Resnest: Split-attention networks[J]. arXiv preprint arXiv:2004.08955, 2020.</p>]]></content>
      
      
      <categories>
          
          <category> Adversarial Attack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> unretricted attack </tag>
            
            <tag> tianchi challenge </tag>
            
            <tag> frequency domain </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CVPR2021 安全AI挑战者计划第六期赛道2：ImageNet无限制对抗攻击 TOP 7 比赛思路</title>
      <link href="/Blog/2021/04/25/tianchi2021top7/"/>
      <url>/Blog/2021/04/25/tianchi2021top7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/Blog/assets/css/APlayer.min.css"><script src="/Blog/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/Blog/assets/js/Meting.min.js"></script><!-- # CVPR2021 安全AI挑战者计划第六期赛道2：ImageNet无限制对抗攻击 TOP 7 比赛思路 --><div align="center"><font size="6">CVPR2021 安全AI挑战者计划第六期赛道2：ImageNet无限制对抗攻击 TOP 7 比赛思路</font></div><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>深度学习在当下许多视觉任务中都取得了卓越的性能，但是深度神经网络很容易遭受输入上微小和不可察觉的干扰导致的误分类（对抗样本）。而事实上，无限制的对抗样本（对图像进行大范围且可见的修改）往往会对深度学习模型的安全性产生更大的威胁，因为其会使得模型误识别的同时不影响人的正常观察。无限制对抗攻击是近两年来对抗领域的一个热门方向，本次比赛意图在纯黑盒模型的模式下对ImageNet上的无限制对抗攻击场景进行进一步的探索，可以进一步提炼并总结无限制攻击的一些创新而有效的方案，在学术上推动对抗攻击领域的发展。</p><h2 id="赛题分析"><a href="#赛题分析" class="headerlink" title="赛题分析"></a>赛题分析</h2><ol><li>比赛攻击形式为无限制攻击，因此可以采取生成、变换、Patch攻击、扰动等各种不同的攻击方法。</li><li>比赛引入了对图像质量的评价标准，在初赛和复赛中采取客观评价指标，主要是由 FID（自然真实程度）、LPIPS（和原图的感知距离） 两个指标来衡量，而决赛中采用主观评价指标，依靠专家直接对图像进行打分来评判。因此靠拟合客观分实际也是没用的。</li><li>比赛为纯黑盒攻击，无法拿到模型的结构信息及梯度信息，同时也无法获得模型对某输入的输出，因此只能依靠提高攻击方法的迁移能力来提高攻击成功率。</li></ol><h2 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h2><ol><li>通过尝试我们发现，perturbation的攻击方式反而在攻击成功率与图像质量的综合表现上更加，因此我们的主体方案都是围绕perturbation的攻击方式。为了保证迁移能力，我们主体采用的是DI-MI-FGSM[1]（简称DIM），采用动量因子$\mu=1.0$，输入变换概率$p=0.7$，迭代次数为$n=80$，扰动上限为$\epsilon=16/255$。</li><li>通过对loss的尝试，我们发现，CW loss[2]相较于CE loss，能在不明显损失图像质量的情况下较大幅度提高样本的攻击成功率（白盒+黑盒），其他一些loss（如DLR loss[3]）相较于CW loss无明显提升，因此我们最终采用CW loss。值得一提的是，我们没有将客观指标引入loss，因为过拟合客观指标对于决赛是不利的。</li><li>考虑到黑盒模型中可能包含一些防御模型，我们尝试了Translation-Invariant[4]（简称TI）方法，该方法能较大的提高攻击方法在防御模型上的迁移能力。我们将TI方法与DIM方法结合得到TI-DIM，但在实际测试中，其并没有表现出对迁移能力的提高，有可能是黑盒模型中并没有设置防御模型。同时，TI方法对于noise的滤波会导致perturbation更明显，降低图像质量，因此我们最终没有采用。</li><li>对于$L_p$范数的探讨，从经验而言，$L_2$范数下生成的对抗样本图像质量会略优于$L_\infty$范数。在实际尝试时，感觉两者并无太大的差异，最终还是采用$L_\infty$范数。</li><li>图像预处理部分，首先对图像进行resize时，我们发现双三次插值（Bicubic）相比双线性插值（Bilinear）和最邻近插值（Nearest），效果更好。其次，考虑到比赛可能会对noise类型的攻击进行限制，我们在预处理部分引入了gaussian_blur，并令其参与到梯度更新图之中。</li><li>为了进一步提高模型的迁移能力，我们使用了Model Ensemble方法，通过集成不同模型的logits进行攻击。尝试中发现，集成当前SOTA的大模型（efficientnet、vit等），相比集成更多的小模型效果更好。</li></ol><h2 id="结果总结"><a href="#结果总结" class="headerlink" title="结果总结"></a>结果总结</h2><ul><li>代码分享：<a href="https://github.com/Wenzhao-Xiang/transfer_attack_for_tianchi2021" target="_blank" rel="noopener">https://github.com/Wenzhao-Xiang/transfer_attack_for_tianchi2021</a></li></ul><h2 id="样本展示"><a href="#样本展示" class="headerlink" title="样本展示"></a>样本展示</h2><table><thead><tr><th>原始图像</th><th>对抗样本</th></tr></thead><tbody><tr><td><a href="https://tvax1.sinaimg.cn/large/a0732b55ly1gpvxylvjwhj20dw0dwwfu.jpg" data-fancybox="group" data-caption="0" class="fancybox"><img alt="0" title="0" data-src="https://tvax1.sinaimg.cn/large/a0732b55ly1gpvxylvjwhj20dw0dwwfu.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva1.sinaimg.cn/large/a0732b55ly1gpvy02sftwj20dw0dwmyq.jpg" data-fancybox="group" data-caption="0" class="fancybox"><img alt="0" title="0" data-src="https://tva1.sinaimg.cn/large/a0732b55ly1gpvy02sftwj20dw0dwmyq.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr><tr><td><a href="https://tva3.sinaimg.cn/large/a0732b55ly1gpvxzg2p5ij20dw0dwwev.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" title="5" data-src="https://tva3.sinaimg.cn/large/a0732b55ly1gpvxzg2p5ij20dw0dwwev.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva4.sinaimg.cn/large/a0732b55ly1gpvy07ytnhj20dw0dw3zf.jpg" data-fancybox="group" data-caption="5" class="fancybox"><img alt="5" title="5" data-src="https://tva4.sinaimg.cn/large/a0732b55ly1gpvy07ytnhj20dw0dw3zf.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr><tr><td><a href="https://tvax4.sinaimg.cn/large/a0732b55ly1gpvxzrg53fj20dw0dwt9j.jpg" data-fancybox="group" data-caption="26" class="fancybox"><img alt="26" title="26" data-src="https://tvax4.sinaimg.cn/large/a0732b55ly1gpvxzrg53fj20dw0dwt9j.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td><td><a href="https://tva2.sinaimg.cn/large/a0732b55ly1gpvy0e4temj20dw0dwwfo.jpg" data-fancybox="group" data-caption="26" class="fancybox"><img alt="26" title="26" data-src="https://tva2.sinaimg.cn/large/a0732b55ly1gpvy0e4temj20dw0dwwfo.jpg" src="https://tvax2.sinaimg.cn/large/a0732b55ly1gbun1i69ssg209g09gmy4.gif" class="lazyload"></a></td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Xie, Cihang, et al. “Improving transferability of adversarial examples with input diversity.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.</p><p>[2] Carlini N ,  Wagner D . Towards Evaluating the Robustness of Neural Networks[J]. IEEE, 2017.</p><p>[3] Croce F, Hein M. Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks[C]//International Conference on Machine Learning. PMLR, 2020: 2206-2216.</p><p>[4] Dong Y, Pang T, Su H, et al. Evading defenses to transferable adversarial examples by translation-invariant attacks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 4312-4321.</p>]]></content>
      
      
      <categories>
          
          <category> Adversarial Attack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> unretricted attack </tag>
            
            <tag> tianchi challenge </tag>
            
            <tag> perturbation-based attack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GSoC2019 - Improve the performance of JavaScript version of OpenCV (OpenCV.js)</title>
      <link href="/Blog/2020/02/01/gsoc2019/"/>
      <url>/Blog/2020/02/01/gsoc2019/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/Blog/assets/css/APlayer.min.css"><script src="/Blog/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/Blog/assets/js/Meting.min.js"></script><!-- # [GSoC 2019] Improve the performance of JavaScript version of OpenCV (OpenCV.js) --><!-- #### Wenzhao-Xiang | [github](https://github.com/Wenzhao-Xiang) | [twitter](https://twitter.com/Wenzhao_Xiang) | [email](mailto:winzard35@gmail.com) --><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul><li><a href="https://summerofcode.withgoogle.com/projects/#5715812734730240" target="_blank" rel="noopener">Project Link</a></li><li>Proposal:  <a href="https://docs.google.com/document/d/1Nx3MDFnM47kumdyyUzju2xn3loiZnf0HsmhmCzAJfKo/edit?usp=sharing" target="_blank" rel="noopener">Improve the performance of JavaScript version of OpenCV (OpenCV.js)</a></li><li>Mentor: Ningxin Hu, Vitaly Tuzov</li><li>Organization: OpenCV</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://docs.opencv.org/3.4/df/d0a/tutorial_js_intro.html" target="_blank" rel="noopener">OpenCV.js</a> is a JavaScript binding for selected subset of OpenCV functions for the web platform. It allows emerging web applications with multimedia processing to benefit from the wide variety of vision functions available in OpenCV. OpenCV.js leverages Emscripten to compile OpenCV functions into asm.js or WebAssembly targets, and provides a JavaScript APIs for web application to access them.</p><p>However, now the performance of OpenCV.js still have a big gap with Native, and it can’t support real-time tasks very well, such as face detection and face recognition. The biggest reason is that the current version of OpenCV.js runs with single thread and no SIMD, which greatly wastes the parallel computing power of the CPU.</p><p>But at this time, WebAssembly can reduce the performance gap between Web and Native. WebAssembly now support multi-threading with Web Worker and shareArrayBuffer, and is going on supporting new v128 value types used for SIMD, which can both improve the parallel computing capability on Web.</p><p>Therefore, the main goal of this project is to speedup OpenCV.js by multi-threading and SIMD.</p><h2 id="Work-structure"><a href="#Work-structure" class="headerlink" title="Work structure"></a>Work structure</h2><h3 id="Create-the-base-of-OpenCV-js-performance-test"><a href="#Create-the-base-of-OpenCV-js-performance-test" class="headerlink" title="Create the base of OpenCV.js performance test"></a>Create the base of OpenCV.js performance test</h3><p><a href="https://benchmarkjs.com" target="_blank" rel="noopener">Benchmark.js</a> is a benchmarking library that supports high-resolution timers &amp; returns statistically significant results. And the OpenCV.js performance test tool is based on it. Now we add three kernels of imgproc module into these performance test, which are <code>cvtColor</code>, <code>Resize</code> and <code>Threshold</code>. And all the performance tests are based on native performance test.</p><p>To run performance tests, launch a local web server in &lt;build_dir&gt;/bin folder. For example, node http-server which serves on <code>localhost:8080</code>. If you want to test <code>threshold</code>, please navigate the web browser to <code>http://localhost:8080/perf/perf_imgproc/perf_threshold.html</code>. You need to input the test parameter like <code>(1920x1080, CV_8UC1, THRESH_BINARY)</code>, and then click the <code>Run</code> button to run the case. And if you don’t input the parameter, it will run all the cases of this kernel.</p><p>You can also run tests using Node.js. For example, run <code>threshold</code> with parameter <code>(1920x1080, CV_8UC1, THRESH_BINARY)</code>:</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sh</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> bin/perf</span><br><span class="line">npm install</span><br><span class="line">node perf_threshold.js --test_param_filter=<span class="string">"(1920x1080, CV_8UC1, THRESH_BINARY)"</span></span><br></pre></td></tr></table></figure></div><h3 id="Optimize-the-OpenCV-js-performance-by-WebAssembly-threads"><a href="#Optimize-the-OpenCV-js-performance-by-WebAssembly-threads" class="headerlink" title="Optimize the OpenCV.js performance by WebAssembly threads"></a>Optimize the OpenCV.js performance by WebAssembly threads</h3><p>WebAssembly now support multi-threading with Web Worker and SharedArrayBuffer (i.e., <a href="https://github.com/WebAssembly/threads" target="_blank" rel="noopener">WebAssembly threads</a>). Developers are able to use Emscripten to translate the pthreads based native code to Web Workers and SharedArrayBuffer based WebAssembly code. So we leverage this capability to translate <a href="https://docs.opencv.org/3.4.1/d7/dff/tutorial_how_to_use_OpenCV_parallel_for_.html" target="_blank" rel="noopener">OpenCV pthreads API</a> implementation into equivalent WebAssembly code by using Web Workers with SharedArrayBuffer. The multithreading version of OpenCV.js will have a pool of Web Workers and will schedule a worker when a new thread is being spawn. And this optimization can only be used in browser as node.js have no Web Worker API.</p><p>We expose two new API <code>cv.parallel_pthreads_set_threads_num(number)</code> and <code>cv.parallel_pthreads_get_threads_num()</code>, so we can use the former to set threads number dynamically and use the latter to get the current threads number. And the default threads number is the logic core number of the device.</p><h3 id="Optimize-the-OpenCV-js-performance-by-WebAssembly-SIMD"><a href="#Optimize-the-OpenCV-js-performance-by-WebAssembly-SIMD" class="headerlink" title="Optimize the OpenCV.js performance by WebAssembly SIMD"></a>Optimize the OpenCV.js performance by WebAssembly SIMD</h3><p>WebAssembly is adding the support of SIMD128 instructions (i.e., <a href="https://github.com/WebAssembly/simd/blob/master/proposals/simd/SIMD.md" target="_blank" rel="noopener">WebAssembly SIMD</a>). This features has been landed in V8/Chromium behind a developer flag. On the tooling side, the WebAssembly SIMD builtins has been added to LLVM compiler and Emscripten has released the first version of WebAssembly intrinsics. So we can use Emscripten LLVM upstream backend to translate the native vectorization implementation to WebAssembly SIMD128 instructions and deploy them to browsers.</p><p>Today’s OpenCV Universal intrinsics implementation have multiple backends for different architectures, such as SSE, NEON, AXV and VSX. Therefore, we added a new WebAssembly SIMD backend by using LLVM WebAssembly builtins and WebAssembly intrinsics.</p><p>We also enabled the WebAssembly intrinsics tests by compiling the native intrinsics tests to WebAssembly. With this tool, we can easily test whether our WebAssembly backend implementation of Universal Intrinsics is right. And now it pass all the tests.</p><p>The SIMD optimization is experimental as WebAssembly SIMD is still in development. Therefore, the simd version of OpenCV.js built by latest LLVM upstream may not work with the stable browser or old version of Node.js. Please use the latest version of unstable browser or Node.js to get new features, like <code>Chrome Dev</code>.</p><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>For OpenCV kernels, take <code>Threshold</code> kernel with parameter <code>(1920x1080, CV_8UC1, THRESH_BINARY)</code> as example:</p><p>OS: Ubuntu 16.04.5<br><br>Emscripten: 1.38.42, LLVM upstream backend<br><br>Browser: Chrome, Version 78.0.3880.4 (Official Build) dev (64-bit)<br><br>Hardware: Core(TM) i7-8700 CPU @ 3.20GHz with 12 logical cores:</p><table><thead><tr><th>OpenCV.js Build</th><th>Mean Time (ms)</th><th>Speedup (to scalar)</th></tr></thead><tbody><tr><td>scalar</td><td>1.164</td><td>1</td></tr><tr><td>threads</td><td>0.261</td><td>4.45</td></tr><tr><td>simd</td><td>0.123</td><td>9.46</td></tr><tr><td>threads + simd</td><td>0.039</td><td>29.84</td></tr></tbody></table><p>For real case, take OpenCV.js face recognition sample as example:</p><p>OS: Ubuntu Linux 16.04.5<br><br>Emscripten: 1.38.42, LLVM upstream backend<br><br>Browser: Chrome, Version 78.0.3880.4 (Official Build) dev (64-bit)<br><br>Hardware: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz with 12 logical cores</p><table><thead><tr><th>OpenCV.js Build</th><th>FPS</th><th>Speedup (to scalar)</th></tr></thead><tbody><tr><td>scalar</td><td>3</td><td>1</td></tr><tr><td>threads</td><td>10</td><td>3.33</td></tr><tr><td>simd</td><td>12</td><td>4</td></tr><tr><td>threads + simd</td><td>26</td><td>8.6</td></tr></tbody></table><h2 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h2><ol><li><p>Add more modules and kernels into performance test, like <code>core</code>, <code>feature2d</code>, <code>video</code> and so on.</p></li><li><p>Optimize the Universal Intrinsics WebAssembly backend with the development of WebAssembly SIMD.</p></li></ol><h2 id="OpenCV-js-Demos"><a href="#OpenCV-js-Demos" class="headerlink" title="OpenCV.js Demos"></a>OpenCV.js Demos</h2><p><a href="https://wenzhao-xiang.github.io/opencvjs/index.html">OpenCV.js Demos</a> (May need the latest version of Chrome-Dev)<br><br><a href="https://youtu.be/ertdEzqE6bI" target="_blank" rel="noopener">My video report for GSoC on Youtube</a></p><h2 id="Commits-List"><a href="#Commits-List" class="headerlink" title="Commits List"></a>Commits List</h2><p><a href="https://github.com/opencv/opencv/pull/15371" target="_blank" rel="noopener">The PR</a><br><br><a href="https://github.com/Wenzhao-Xiang/opencv/commit/82e98faa65ba070a83d6d040be778f2b1fab6e29" target="_blank" rel="noopener">The list of my commits</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> opencvjs </tag>
            
            <tag> webassembly </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
